{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0a562d-2cd8-45ec-ab47-085619f49424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: fake_almaden\n",
      "Computing kernel matrix using FakeAlmadenV2 simulator...\n",
      "Fidelity (0, 0): 0.9788\n",
      "Fidelity (0, 1): 0.5386\n",
      "Fidelity (0, 2): 0.8860\n",
      "Fidelity (0, 3): 0.7153\n",
      "Fidelity (0, 4): 0.7720\n",
      "Fidelity (0, 5): 0.9766\n",
      "Fidelity (0, 6): 0.7859\n",
      "Fidelity (0, 7): 0.2627\n",
      "Fidelity (0, 8): 0.8259\n",
      "Fidelity (0, 9): 0.9736\n",
      "Fidelity (0, 10): 0.9746\n",
      "Fidelity (0, 11): 0.5984\n",
      "Fidelity (0, 12): 0.8926\n",
      "Fidelity (0, 13): 0.9404\n",
      "Fidelity (0, 14): 0.5586\n",
      "Fidelity (0, 15): 0.8823\n",
      "Fidelity (1, 0): 0.5269\n",
      "Fidelity (1, 1): 0.9829\n",
      "Fidelity (1, 2): 0.8105\n",
      "Fidelity (1, 3): 0.0977\n",
      "Fidelity (1, 4): 0.9099\n",
      "Fidelity (1, 5): 0.6213\n",
      "Fidelity (1, 6): 0.1516\n",
      "Fidelity (1, 7): 0.8896\n",
      "Fidelity (1, 8): 0.8701\n",
      "Fidelity (1, 9): 0.4607\n",
      "Fidelity (1, 10): 0.4387\n",
      "Fidelity (1, 11): 0.0654\n",
      "Fidelity (1, 12): 0.8022\n",
      "Fidelity (1, 13): 0.3545\n",
      "Fidelity (1, 14): 0.9819\n",
      "Fidelity (1, 15): 0.2273\n",
      "Fidelity (2, 0): 0.8860\n",
      "Fidelity (2, 1): 0.8101\n",
      "Fidelity (2, 2): 0.9810\n",
      "Fidelity (2, 3): 0.4199\n",
      "Fidelity (2, 4): 0.9485\n",
      "Fidelity (2, 5): 0.9297\n",
      "Fidelity (2, 6): 0.4983\n",
      "Fidelity (2, 7): 0.5503\n",
      "Fidelity (2, 8): 0.9705\n",
      "Fidelity (2, 9): 0.8472\n",
      "Fidelity (2, 10): 0.8362\n",
      "Fidelity (2, 11): 0.2930\n",
      "Fidelity (2, 12): 0.9783\n",
      "Fidelity (2, 13): 0.7527\n",
      "Fidelity (2, 14): 0.8420\n",
      "Fidelity (2, 15): 0.6340\n",
      "Fidelity (3, 0): 0.7090\n",
      "Fidelity (3, 1): 0.1064\n",
      "Fidelity (3, 2): 0.4229\n",
      "Fidelity (3, 3): 0.9807\n",
      "Fidelity (3, 4): 0.2568\n",
      "Fidelity (3, 5): 0.6431\n",
      "Fidelity (3, 6): 0.9692\n",
      "Fidelity (3, 7): 0.0635\n",
      "Fidelity (3, 8): 0.3325\n",
      "Fidelity (3, 9): 0.7656\n",
      "Fidelity (3, 10): 0.7803\n",
      "Fidelity (3, 11): 0.9585\n",
      "Fidelity (3, 12): 0.4392\n",
      "Fidelity (3, 13): 0.8599\n",
      "Fidelity (3, 14): 0.1162\n",
      "Fidelity (3, 15): 0.9321\n",
      "Fidelity (4, 0): 0.7737\n",
      "Fidelity (4, 1): 0.9209\n",
      "Fidelity (4, 2): 0.9478\n",
      "Fidelity (4, 3): 0.2800\n",
      "Fidelity (4, 4): 0.9783\n",
      "Fidelity (4, 5): 0.8291\n",
      "Fidelity (4, 6): 0.3467\n",
      "Fidelity (4, 7): 0.7085\n",
      "Fidelity (4, 8): 0.9741\n",
      "Fidelity (4, 9): 0.7009\n",
      "Fidelity (4, 10): 0.6946\n",
      "Fidelity (4, 11): 0.1746\n",
      "Fidelity (4, 12): 0.9438\n",
      "Fidelity (4, 13): 0.6016\n",
      "Fidelity (4, 14): 0.9282\n",
      "Fidelity (4, 15): 0.4612\n",
      "Fidelity (5, 0): 0.9758\n",
      "Fidelity (5, 1): 0.6038\n",
      "Fidelity (5, 2): 0.9277\n",
      "Fidelity (5, 3): 0.6365\n",
      "Fidelity (5, 4): 0.8154\n",
      "Fidelity (5, 5): 0.9771\n",
      "Fidelity (5, 6): 0.7068\n",
      "Fidelity (5, 7): 0.3318\n",
      "Fidelity (5, 8): 0.8735\n",
      "Fidelity (5, 9): 0.9595\n",
      "Fidelity (5, 10): 0.9565\n",
      "Fidelity (5, 11): 0.5149\n",
      "Fidelity (5, 12): 0.9353\n",
      "Fidelity (5, 13): 0.9089\n",
      "Fidelity (5, 14): 0.6411\n",
      "Fidelity (5, 15): 0.8152\n",
      "Fidelity (6, 0): 0.7898\n",
      "Fidelity (6, 1): 0.1477\n",
      "Fidelity (6, 2): 0.5046\n",
      "Fidelity (6, 3): 0.9709\n",
      "Fidelity (6, 4): 0.3511\n",
      "Fidelity (6, 5): 0.7129\n",
      "Fidelity (6, 6): 0.9822\n",
      "Fidelity (6, 7): 0.0586\n",
      "Fidelity (6, 8): 0.4048\n",
      "Fidelity (6, 9): 0.8225\n",
      "Fidelity (6, 10): 0.8430\n",
      "Fidelity (6, 11): 0.9236\n",
      "Fidelity (6, 12): 0.5173\n",
      "Fidelity (6, 13): 0.9001\n",
      "Fidelity (6, 14): 0.1707\n",
      "Fidelity (6, 15): 0.9590\n",
      "Fidelity (7, 0): 0.2629\n",
      "Fidelity (7, 1): 0.9045\n",
      "Fidelity (7, 2): 0.5398\n",
      "Fidelity (7, 3): 0.0571\n",
      "Fidelity (7, 4): 0.7078\n",
      "Fidelity (7, 5): 0.3303\n",
      "Fidelity (7, 6): 0.0559\n",
      "Fidelity (7, 7): 0.9812\n",
      "Fidelity (7, 8): 0.6387\n",
      "Fidelity (7, 9): 0.2319\n",
      "Fidelity (7, 10): 0.1997\n",
      "Fidelity (7, 11): 0.0962\n",
      "Fidelity (7, 12): 0.5291\n",
      "Fidelity (7, 13): 0.1233\n",
      "Fidelity (7, 14): 0.8772\n",
      "Fidelity (7, 15): 0.0767\n",
      "Fidelity (8, 0): 0.8242\n",
      "Fidelity (8, 1): 0.8762\n",
      "Fidelity (8, 2): 0.9707\n",
      "Fidelity (8, 3): 0.3308\n",
      "Fidelity (8, 4): 0.9778\n",
      "Fidelity (8, 5): 0.8674\n",
      "Fidelity (8, 6): 0.4038\n",
      "Fidelity (8, 7): 0.6433\n",
      "Fidelity (8, 8): 0.9846\n",
      "Fidelity (8, 9): 0.7742\n",
      "Fidelity (8, 10): 0.7524\n",
      "Fidelity (8, 11): 0.2195\n",
      "Fidelity (8, 12): 0.9673\n",
      "Fidelity (8, 13): 0.6616\n",
      "Fidelity (8, 14): 0.8782\n",
      "Fidelity (8, 15): 0.5315\n",
      "Fidelity (9, 0): 0.9763\n",
      "Fidelity (9, 1): 0.4729\n",
      "Fidelity (9, 2): 0.8525\n",
      "Fidelity (9, 3): 0.7708\n",
      "Fidelity (9, 4): 0.7273\n",
      "Fidelity (9, 5): 0.9592\n",
      "Fidelity (9, 6): 0.8220\n",
      "Fidelity (9, 7): 0.2126\n",
      "Fidelity (9, 8): 0.7603\n",
      "Fidelity (9, 9): 0.9790\n",
      "Fidelity (9, 10): 0.9807\n",
      "Fidelity (9, 11): 0.6479\n",
      "Fidelity (9, 12): 0.8469\n",
      "Fidelity (9, 13): 0.9646\n",
      "Fidelity (9, 14): 0.5034\n",
      "Fidelity (9, 15): 0.9158\n",
      "Fidelity (10, 0): 0.9724\n",
      "Fidelity (10, 1): 0.4478\n",
      "Fidelity (10, 2): 0.8364\n",
      "Fidelity (10, 3): 0.7832\n",
      "Fidelity (10, 4): 0.7007\n",
      "Fidelity (10, 5): 0.9495\n",
      "Fidelity (10, 6): 0.8401\n",
      "Fidelity (10, 7): 0.1960\n",
      "Fidelity (10, 8): 0.7627\n",
      "Fidelity (10, 9): 0.9768\n",
      "Fidelity (10, 10): 0.9812\n",
      "Fidelity (10, 11): 0.6770\n",
      "Fidelity (10, 12): 0.8433\n",
      "Fidelity (10, 13): 0.9666\n",
      "Fidelity (10, 14): 0.4597\n",
      "Fidelity (10, 15): 0.9180\n",
      "Fidelity (11, 0): 0.5947\n",
      "Fidelity (11, 1): 0.0647\n",
      "Fidelity (11, 2): 0.3022\n",
      "Fidelity (11, 3): 0.9631\n",
      "Fidelity (11, 4): 0.1821\n",
      "Fidelity (11, 5): 0.5171\n",
      "Fidelity (11, 6): 0.9312\n",
      "Fidelity (11, 7): 0.0908\n",
      "Fidelity (11, 8): 0.2192\n",
      "Fidelity (11, 9): 0.6460\n",
      "Fidelity (11, 10): 0.6592\n",
      "Fidelity (11, 11): 0.9817\n",
      "Fidelity (11, 12): 0.3035\n",
      "Fidelity (11, 13): 0.7659\n",
      "Fidelity (11, 14): 0.0662\n",
      "Fidelity (11, 15): 0.8628\n",
      "Fidelity (12, 0): 0.8926\n",
      "Fidelity (12, 1): 0.8030\n",
      "Fidelity (12, 2): 0.9785\n",
      "Fidelity (12, 3): 0.4390\n",
      "Fidelity (12, 4): 0.9453\n",
      "Fidelity (12, 5): 0.9324\n",
      "Fidelity (12, 6): 0.5066\n",
      "Fidelity (12, 7): 0.5444\n",
      "Fidelity (12, 8): 0.9678\n",
      "Fidelity (12, 9): 0.8455\n",
      "Fidelity (12, 10): 0.8286\n",
      "Fidelity (12, 11): 0.3059\n",
      "Fidelity (12, 12): 0.9822\n",
      "Fidelity (12, 13): 0.7529\n",
      "Fidelity (12, 14): 0.8215\n",
      "Fidelity (12, 15): 0.6233\n",
      "Fidelity (13, 0): 0.9402\n",
      "Fidelity (13, 1): 0.3555\n",
      "Fidelity (13, 2): 0.7593\n",
      "Fidelity (13, 3): 0.8674\n",
      "Fidelity (13, 4): 0.5981\n",
      "Fidelity (13, 5): 0.9021\n",
      "Fidelity (13, 6): 0.9094\n",
      "Fidelity (13, 7): 0.1387\n",
      "Fidelity (13, 8): 0.6707\n",
      "Fidelity (13, 9): 0.9626\n",
      "Fidelity (13, 10): 0.9685\n",
      "Fidelity (13, 11): 0.7571\n",
      "Fidelity (13, 12): 0.7612\n",
      "Fidelity (13, 13): 0.9795\n",
      "Fidelity (13, 14): 0.3752\n",
      "Fidelity (13, 15): 0.9592\n",
      "Fidelity (14, 0): 0.5549\n",
      "Fidelity (14, 1): 0.9749\n",
      "Fidelity (14, 2): 0.8201\n",
      "Fidelity (14, 3): 0.1157\n",
      "Fidelity (14, 4): 0.9255\n",
      "Fidelity (14, 5): 0.6282\n",
      "Fidelity (14, 6): 0.1560\n",
      "Fidelity (14, 7): 0.8794\n",
      "Fidelity (14, 8): 0.8965\n",
      "Fidelity (14, 9): 0.4973\n",
      "Fidelity (14, 10): 0.4810\n",
      "Fidelity (14, 11): 0.0657\n",
      "Fidelity (14, 12): 0.8164\n",
      "Fidelity (14, 13): 0.3789\n",
      "Fidelity (14, 14): 0.9810\n",
      "Fidelity (14, 15): 0.2622\n",
      "Fidelity (15, 0): 0.8767\n",
      "Fidelity (15, 1): 0.2280\n",
      "Fidelity (15, 2): 0.6270\n",
      "Fidelity (15, 3): 0.9348\n",
      "Fidelity (15, 4): 0.4536\n",
      "Fidelity (15, 5): 0.8215\n",
      "Fidelity (15, 6): 0.9614\n",
      "Fidelity (15, 7): 0.0757\n",
      "Fidelity (15, 8): 0.5315\n",
      "Fidelity (15, 9): 0.8994\n",
      "Fidelity (15, 10): 0.9075\n",
      "Fidelity (15, 11): 0.8645\n",
      "Fidelity (15, 12): 0.6289\n",
      "Fidelity (15, 13): 0.9536\n",
      "Fidelity (15, 14): 0.2642\n",
      "Fidelity (15, 15): 0.9834\n",
      "Fidelity (0, 0): 0.2888\n",
      "Fidelity (0, 1): 0.9233\n",
      "Fidelity (0, 2): 0.5828\n",
      "Fidelity (0, 3): 0.0632\n",
      "Fidelity (0, 4): 0.7476\n",
      "Fidelity (0, 5): 0.3848\n",
      "Fidelity (0, 6): 0.0571\n",
      "Fidelity (0, 7): 0.9778\n",
      "Fidelity (0, 8): 0.6843\n",
      "Fidelity (0, 9): 0.2524\n",
      "Fidelity (0, 10): 0.2190\n",
      "Fidelity (0, 11): 0.0740\n",
      "Fidelity (0, 12): 0.5879\n",
      "Fidelity (0, 13): 0.1621\n",
      "Fidelity (0, 14): 0.9124\n",
      "Fidelity (0, 15): 0.0935\n",
      "Fidelity (1, 0): 0.8132\n",
      "Fidelity (1, 1): 0.8896\n",
      "Fidelity (1, 2): 0.9680\n",
      "Fidelity (1, 3): 0.3147\n",
      "Fidelity (1, 4): 0.9763\n",
      "Fidelity (1, 5): 0.8699\n",
      "Fidelity (1, 6): 0.3938\n",
      "Fidelity (1, 7): 0.6487\n",
      "Fidelity (1, 8): 0.9778\n",
      "Fidelity (1, 9): 0.7678\n",
      "Fidelity (1, 10): 0.7327\n",
      "Fidelity (1, 11): 0.1985\n",
      "Fidelity (1, 12): 0.9653\n",
      "Fidelity (1, 13): 0.6553\n",
      "Fidelity (1, 14): 0.9043\n",
      "Fidelity (1, 15): 0.5017\n",
      "Fidelity (2, 0): 0.9678\n",
      "Fidelity (2, 1): 0.4004\n",
      "Fidelity (2, 2): 0.8047\n",
      "Fidelity (2, 3): 0.8210\n",
      "Fidelity (2, 4): 0.6548\n",
      "Fidelity (2, 5): 0.9414\n",
      "Fidelity (2, 6): 0.8762\n",
      "Fidelity (2, 7): 0.1711\n",
      "Fidelity (2, 8): 0.7219\n",
      "Fidelity (2, 9): 0.9761\n",
      "Fidelity (2, 10): 0.9785\n",
      "Fidelity (2, 11): 0.6931\n",
      "Fidelity (2, 12): 0.8062\n",
      "Fidelity (2, 13): 0.9773\n",
      "Fidelity (2, 14): 0.4302\n",
      "Fidelity (2, 15): 0.9387\n",
      "Fidelity (3, 0): 0.7705\n",
      "Fidelity (3, 1): 0.8975\n",
      "Fidelity (3, 2): 0.9585\n",
      "Fidelity (3, 3): 0.3008\n",
      "Fidelity (3, 4): 0.9802\n",
      "Fidelity (3, 5): 0.8345\n",
      "Fidelity (3, 6): 0.3645\n",
      "Fidelity (3, 7): 0.6938\n",
      "Fidelity (3, 8): 0.9790\n",
      "Fidelity (3, 9): 0.7366\n",
      "Fidelity (3, 10): 0.7170\n",
      "Fidelity (3, 11): 0.1951\n",
      "Fidelity (3, 12): 0.9551\n",
      "Fidelity (3, 13): 0.6133\n",
      "Fidelity (3, 14): 0.9185\n",
      "Fidelity (3, 15): 0.4736\n",
      "Test accuracy: 25.00%\n"
     ]
    }
   ],
   "source": [
    "# Importació de llibreries per al tractament de dades i aprenentatge automàtic clàssic\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Importació de components de Qiskit per a la construcció de circuits i càlculs d'observables\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "\n",
    "# Importació del backend simulat i l’estimador de Qiskit Runtime\n",
    "from qiskit_ibm_runtime import EstimatorV2 as Estimator\n",
    "from qiskit_ibm_runtime.fake_provider import FakeAlmadenV2\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1. Generació i pre-processament del conjunt de dades\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Es genera un conjunt de dades sintètic de dues dimensions no linealment separables\n",
    "X, y = make_moons(n_samples=20, noise=0.1, random_state=0)\n",
    "\n",
    "# S’estandarditzen les dades per a garantir una codificació quàntica òptima\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Es divideixen les dades en conjunt d’entrenament i conjunt de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2. Definició del circuit de codificació (feature map)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Es defineix una funció que implementa un mapa de característiques quàntic senzill\n",
    "# mitjançant rotacions Ry i Rz combinades amb una porta CZ per generar entrellaçament\n",
    "def feature_map(x):\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.ry(x[0], 0)\n",
    "    qc.rz(x[1], 1)\n",
    "    qc.cz(0, 1)\n",
    "    return qc\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3. Implementació de la funció de càlcul de la fidelitat\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Aquesta funció calcula la fidelitat entre dues mostres codificades quànticament\n",
    "# utilitzant la primitiva EstimatorV2 sobre un backend simulat amb layout físic realista\n",
    "def kernel_fidelity_estimator(x1, x2, estimator, pm):\n",
    "    # Es construeix el circuit combinat U(x1)·U†(x2)\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.append(feature_map(x1), [0, 1])\n",
    "    qc.append(feature_map(x2).inverse(), [0, 1])\n",
    "\n",
    "    # Es defineix un observable compost per les combinacions de Pauli que permet mesurar la fidelitat\n",
    "    observable = SparsePauliOp.from_list([\n",
    "        (\"II\", 0.25),\n",
    "        (\"IZ\", 0.25),\n",
    "        (\"ZI\", 0.25),\n",
    "        (\"ZZ\", 0.25)\n",
    "    ])\n",
    "\n",
    "    # El circuit es transpila per adaptar-se al layout físic del backend simulat\n",
    "    isa_circuit = pm.run(qc)\n",
    "    mapped_observable = observable.apply_layout(isa_circuit.layout)\n",
    "\n",
    "    # L’estimador s’utilitza per obtenir el valor esperat (fidelitat) del circuit\n",
    "    job = estimator.run([(isa_circuit, mapped_observable)])\n",
    "    pub_result = job.result()[0]\n",
    "    fidelity = pub_result.data.evs\n",
    "\n",
    "    return fidelity.real\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4. Construcció de la matriu de kernel quàntic\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Aquesta funció construeix la matriu simètrica de fidelitats entre parelles de mostres\n",
    "# que posteriorment s’utilitzarà com a kernel per a entrenar el model clàssic\n",
    "def compute_kernel_matrix(X1, X2, estimator, pm):\n",
    "    n1, n2 = len(X1), len(X2)\n",
    "    kernel_matrix = np.zeros((n1, n2))\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            fidelity = kernel_fidelity_estimator(X1[i], X2[j], estimator, pm)\n",
    "            kernel_matrix[i, j] = fidelity\n",
    "            print(f\"Fidelity ({i}, {j}): {fidelity:.4f}\")\n",
    "    return kernel_matrix\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5. Inicialització del backend i entorn de simulació\n",
    "# ------------------------------------------------------\n",
    "backend = FakeAlmadenV2()\n",
    "print(f\"Using backend: {backend.name}\")\n",
    "estimator = Estimator(backend)\n",
    "pm = generate_preset_pass_manager(backend=backend, optimization_level=1)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6. Entrenament i avaluació del model amb SVM\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Es calcula la matriu de kernel quàntic utilitzant la fidelitat entre estats codificats\n",
    "print(\"Computing kernel matrix using FakeAlmadenV2 simulator...\")\n",
    "K_train = compute_kernel_matrix(X_train, X_train, estimator, pm)\n",
    "K_test = compute_kernel_matrix(X_test, X_train, estimator, pm)\n",
    "\n",
    "# Es construeix un model SVM amb kernel precomputat (la matriu de fidelitat quàntica)\n",
    "svc = SVC(kernel='precomputed')\n",
    "svc.fit(K_train, y_train)\n",
    "\n",
    "# Es realitza la predicció i es calcula l’accuràcia sobre el conjunt de test\n",
    "y_pred = svc.predict(K_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiskit-env)",
   "language": "python",
   "name": "qiskit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
